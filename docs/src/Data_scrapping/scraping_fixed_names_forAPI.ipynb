{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import datetime as dt\n",
    "import time\n",
    "from random import randint\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the contents of CSPP_breakdown_by_sector_rating_country excel sheets into seperate dataframes\n",
    "q1_2021_df = pd.read_excel (r'/Users/gabbyvinco/Desktop/CSPP_breakdown_by_sector_rating_country(1).xlsx', sheet_name='CSPP_breakdown_Q1_2021')\n",
    "q3_2020_df = pd.read_excel (r'/Users/gabbyvinco/Desktop/CSPP_breakdown_by_sector_rating_country(1).xlsx', sheet_name='CSPP_breakdown_Q3_2020')\n",
    "q1_2020_df = pd.read_excel (r'/Users/gabbyvinco/Desktop/CSPP_breakdown_by_sector_rating_country(1).xlsx', sheet_name='CSPP_breakdown_Q1_2020')\n",
    "q3_2019_df = pd.read_excel (r'/Users/gabbyvinco/Desktop/CSPP_breakdown_by_sector_rating_country(1).xlsx', sheet_name='CSPP_breakdown_Q3_2019')\n",
    "q1_2019_df = pd.read_excel (r'/Users/gabbyvinco/Desktop/CSPP_breakdown_by_sector_rating_country(1).xlsx', sheet_name='CSPP_breakdown_Q1_2019')\n",
    "q3_2018_df = pd.read_excel (r'/Users/gabbyvinco/Desktop/CSPP_breakdown_by_sector_rating_country(1).xlsx', sheet_name='CSPP_breakdown_Q3_2018')\n",
    "q1_2018_df = pd.read_excel (r'/Users/gabbyvinco/Desktop/CSPP_breakdown_by_sector_rating_country(1).xlsx', sheet_name='CSPP_breakdown_Q1_2018')\n",
    "q3_2017_df = pd.read_excel (r'/Users/gabbyvinco/Desktop/CSPP_breakdown_by_sector_rating_country(1).xlsx', sheet_name='CSPP_breakdown_Q3_2017')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the contents of CSPP_PEPP_corporate_bond_holdings_20210430 into a dataframe\n",
    "corporate_bond_holdings_df = pd.read_excel (r'/Users/gabbyvinco/Desktop/CSPP_PEPP_corporate_bond_holdings_20210430.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove accents from companies in ISSUER column\n",
    "corporate_bond_holdings_df['ISSUER'] = corporate_bond_holdings_df['ISSUER'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "# corporate_bond_holdings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of unique ISSUERS to run through the API\n",
    "unique_issuers = corporate_bond_holdings_df[\"ISSUER\"].unique()\n",
    "# unique_issuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "organizations_df = pd.DataFrame(unique_issuers)\n",
    "# organizations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df to csv file\n",
    "# organizations_df.to_csv (r'/Users/gabbyvinco/Desktop/unique_companies.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_issuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgs_without_abbrv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to create some rules to fix the issues with company names\n",
    "\n",
    "# drop the acronym on the end of the word\n",
    "for item in unique_issuers:\n",
    "    item = item.split()\n",
    "    if len(item) == 2:\n",
    "        word_count = len(item) \n",
    "        word = item[0]\n",
    "        orgs_without_abbrv.append(word)\n",
    "    if len(item) >= 3:\n",
    "        last_word = len(item) - 1\n",
    "        drop_abbrv = item[:last_word]\n",
    "        drop_abbrv = \" \".join(drop_abbrv)\n",
    "#         print(drop_abbrv)\n",
    "        if \", \" in drop_abbrv:\n",
    "            no_comma = drop_abbrv.split(\", \")\n",
    "            no_comma_str = no_comma[0]\n",
    "#             print(no_comma_str)\n",
    "            orgs_without_abbrv.append(no_comma_str)\n",
    "        else:\n",
    "            orgs_without_abbrv.append(drop_abbrv)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orgs_without_abbrv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Selenium to scrape Google Search to correct names for API search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_issuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_word_unique_issuers = []\n",
    "unique_issuers_count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unique in unique_issuers:\n",
    "    unique = unique.split()\n",
    "    length = len(unique)\n",
    "    unique_issuers_count.append(length)\n",
    "    unique = unique [0]\n",
    "    first_word_unique_issuers.append(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_word_unique_issuers\n",
    "# unique_issuers_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 90.0.4430\n",
      "[WDM] - Get LATEST driver version for 90.0.4430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [/Users/gabbyvinco/.wdm/drivers/chromedriver/mac64/90.0.4430.24/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "# Install and initiate driver\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to test the individual sneaker page functions\n",
    "\n",
    "cbonds_url = 'https://cbonds.com'\n",
    "google_url = 'https://www.google.com/search?q=Holding+de+Infrastructures+de+Transport+S.A.S.&oq=Holding+de+Infrastructures+de+Transport+S.A.S.&aqs=chrome..69i57j69i60.935j0j15&sourceid=chrome&ie=UTF-8'\n",
    "sec_page = 'https://sec.report/CIK/0000313216'\n",
    "my_url = sec_page\n",
    "\n",
    "# open and maximize the browser window\n",
    "driver.get(my_url)\n",
    "# driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the action object\n",
    "action = webdriver.ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a wait with a timeout of 5 seconds\n",
    "wait = WebDriverWait(driver, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bypass agreement\n",
    "time.sleep(3)\n",
    "\n",
    "button = driver.find_element_by_xpath('/html/body/div[3]/div[3]/span/div/div/div[3]/button[2]')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "goog_corrected_names_list = []\n",
    "sidebar_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_name_correction(list):\n",
    "    for item in list:\n",
    "        \n",
    "        goog_search_bar = driver.find_element_by_name(\"q\")\n",
    "        \n",
    "        # small break\n",
    "        sleep(randint(1,2))\n",
    "        \n",
    "        # click search bar\n",
    "        goog_search_bar.click()\n",
    "        \n",
    "        # small break\n",
    "        sleep(randint(1,3))\n",
    "        \n",
    "        # select items in search bar\n",
    "        goog_search_bar.send_keys(Keys.COMMAND, 'a')\n",
    "        \n",
    "        # small break\n",
    "        sleep(randint(1,2))\n",
    "        \n",
    "        # clear search bar\n",
    "        goog_search_bar.send_keys(Keys.BACKSPACE)\n",
    "\n",
    "        # small break\n",
    "        sleep(randint(1,2))\n",
    "        \n",
    "        # type in new item into search bar\n",
    "        goog_search_bar.send_keys(item)\n",
    "        \n",
    "        # small break\n",
    "        sleep(randint(1,2))\n",
    "        \n",
    "        # hit enter and perform search\n",
    "        goog_search_bar.send_keys(Keys.ENTER)\n",
    "        \n",
    "        # break \n",
    "        time.sleep(3)\n",
    "        \n",
    "        # grab entry from page\n",
    "        google_first_entry = driver.find_element_by_class_name('LC20lb')\n",
    "        \n",
    "        goog_text = google_first_entry.text\n",
    "#         print(goog_text)\n",
    "        goog_corrected_names_list.append(goog_text)\n",
    "        \n",
    "        try:\n",
    "            goog_side_info = driver.find_element_by_xpath('/html/body/div[7]/div/div[9]/div[2]/div/div/div[2]/div[1]/div/div[1]/div/div/div[2]/h2')\n",
    "            goog_extra_info = goog_side_info.text\n",
    "#             print(goog_extra_info)\n",
    "            sidebar_info.append(goog_extra_info)\n",
    "        except NoSuchElementException:\n",
    "            no_info = \"no_side_info\"\n",
    "            sidebar_info.append(no_info)\n",
    "            continue\n",
    "            \n",
    "        time.sleep(5)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "google_name_correction(unique_issuers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another variable just incase I overwrite the list\n",
    "goog_unique = sidebar_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exit from the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to add the split info into\n",
    "company_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split the items in goog_unique list\n",
    "for t in goog_unique:\n",
    "    title = t.split(' (')\n",
    "    title = title[0]\n",
    "    company_name.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another variable just incase I overwrite the list\n",
    "# create a count for the loop below\n",
    "goog_search_result = goog_corrected_names_list\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new list to add items to below\n",
    "new_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for items by matching\n",
    "for script in goog_search_result:\n",
    "    corresponding_name = first_word_unique_issuers[count]\n",
    "    find_word = script[script.find(corresponding_name):]\n",
    "    new_list.append(find_word)\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new list to add split items to below\n",
    "# create a count for loop below\n",
    "drop_unneccesary = []\n",
    "new_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through new_list and remove the issues with only one letter\n",
    "for item in new_list:\n",
    "    item = item.split()\n",
    "#     print(item)\n",
    "    if len(item) == 1:\n",
    "        item = \"none\"\n",
    "        drop_unneccesary.append(item)\n",
    "        new_count += 1\n",
    "        pass\n",
    "    else:\n",
    "        number = unique_issuers_count[new_count]\n",
    "#         print(number)\n",
    "        selected_item = item[:number]\n",
    "        selected_item = \" \".join(selected_item)\n",
    "        drop_unneccesary.append(selected_item)\n",
    "        new_count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_unneccesary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lists for the loops to clean the data below\n",
    "dropped_line = []\n",
    "dropped_colon = []\n",
    "dropped_hyphen = []\n",
    "remove_commas = []\n",
    "remove_com = []\n",
    "remove_dot_info = []\n",
    "remove_homepage = []\n",
    "remove_ellipses = []\n",
    "remove_strange_symbol = []\n",
    "remove_2020 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes everything after | from the google results \n",
    "for item in drop_unneccesary:\n",
    "    item = item.split(\"|\")\n",
    "    item = item[0]\n",
    "    dropped_line.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes everything after : from the google results \n",
    "for item in dropped_line:\n",
    "    item = item.split(\":\")\n",
    "    item = item[0]\n",
    "    dropped_colon.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes everything after - from the google results \n",
    "for item in dropped_colon:\n",
    "    item = item.split(\"-\")\n",
    "    item = item[0]\n",
    "    dropped_hyphen.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes everything after , from the google results\n",
    "for item in dropped_hyphen:\n",
    "    item = item.split(\", \")\n",
    "    item = item[0]\n",
    "    remove_commas.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes everything after .com from the google results\n",
    "for item in remove_commas:\n",
    "    item = item.split(\".com\")\n",
    "    item = item[0]\n",
    "    remove_com.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes everything after . Info from the google results\n",
    "for item in remove_com:\n",
    "    item = item.split(\". Info\")\n",
    "    item = item[0]\n",
    "    remove_dot_info.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes everything after Homepage from the google results\n",
    "for item in remove_dot_info:\n",
    "    item = item.split(\"Homepage\")\n",
    "    item = item[0]\n",
    "    remove_homepage.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes everything after ... from the google results\n",
    "for item in remove_homepage:\n",
    "    item = item.split(\"...\")\n",
    "    item = item[0]\n",
    "    remove_ellipses.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes everything after – from the google results\n",
    "for item in remove_ellipses:\n",
    "    item = item.split(\"–\")\n",
    "    item = item[0]\n",
    "    remove_strange_symbol.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes everything after Report 2 from the google results\n",
    "for item in remove_strange_symbol:\n",
    "    item = item.split(\"Report 2\")\n",
    "    item = item[0]\n",
    "    remove_2020.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new list and count for loop below to replace none values\n",
    "compound_list = []\n",
    "name_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to replace none values with items from company_name\n",
    "for item in remove_2020:\n",
    "    if item == \"none\":\n",
    "        side_bar_name = company_name[name_count]\n",
    "        compound_list.append(side_bar_name)\n",
    "        name_count += 1\n",
    "    else:\n",
    "        compound_list.append(item)\n",
    "        name_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compound_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new list and restore count to zero\n",
    "complete_list = []\n",
    "name_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to replace the items with value no_side_info with the values from unique_issuers\n",
    "for item in compound_list:\n",
    "    if item == \"no_side_info\":\n",
    "        og_name = unique_issuers[name_count]\n",
    "        complete_list.append(og_name)\n",
    "        name_count += 1\n",
    "    else:\n",
    "        complete_list.append(item)\n",
    "        name_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check and see how many companies we have in the list\n",
    "len(complete_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add list to dataframe so it can be saved\n",
    "complete_list = pd.DataFrame(complete_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the complete list to csv file\n",
    "# complete_list.to_csv (r'/Users/gabbyvinco/Desktop/google_list.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium Scraping of Cbonds.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of ISIN numbers\n",
    "isin_list = corporate_bond_holdings_df['ISIN'].tolist()\n",
    "# isin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and initiate driver\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to test the individual sneaker page functions\n",
    "my_url = 'https://cbonds.com/'\n",
    "\n",
    "# open and maximize the browser window\n",
    "driver.get(my_url)\n",
    "# driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the action object\n",
    "action = webdriver.ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a wait with a 5 second timeout\n",
    "wait = WebDriverWait(driver, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists to append the text and links into\n",
    "text_list = []\n",
    "href_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to grab the basic info and link to bond page from the popdown in the search bar\n",
    "def scrape_correct_names(isin_list):\n",
    "    for isin in isin_list:\n",
    "        \n",
    "        search_bar = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"mainSearch\"]')))\n",
    "        # click search bar\n",
    "        search_bar.click()\n",
    "        # random sleep time between 1 and 4 seconds\n",
    "        sleep(randint(1,4))\n",
    "        # type in isin number\n",
    "        search_bar.send_keys(isin)\n",
    "        # time sleep 5 seconds\n",
    "        time.sleep(10)\n",
    "        \n",
    "        # grab info from isin entry pop down\n",
    "        pop_down = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[1]/div[4]/div/ul[2]')\n",
    "        pop_down_link = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[1]/div[4]/div/ul[2]/li/a')\n",
    "        text = pop_down.text  \n",
    "        href = pop_down_link.get_attribute('href')\n",
    "        text_list.append(text)\n",
    "        href_list.append(href)\n",
    "        print(text)\n",
    "        print(href)\n",
    "        \n",
    "        # random sleep time between 2 and 6 seconds\n",
    "        sleep(randint(2,6))\n",
    "        \n",
    "        # select all text in the search bar and delete\n",
    "        search_bar.send_keys(Keys.COMMAND, 'a')\n",
    "        search_bar.send_keys(Keys.BACKSPACE)\n",
    "        # random sleep time between 5 and 11 seconds\n",
    "        sleep(randint(5,11))\n",
    "    \n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_correct_names(isin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# href_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new variables just incase they get overwritten\n",
    "all_text = text_list\n",
    "all_links = href_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add it to dataframe so it could be saved\n",
    "scraped_isin_df = pd.DataFrame(isin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the url links to scraped_isin_df as well\n",
    "scraped_isin_df['urlpath'] = all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists to add splitted items from the loop below\n",
    "names = []\n",
    "dates = []\n",
    "percentages = []\n",
    "currencies = []\n",
    "statuses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# takes the data scraped and splits it into variables regarding the content\n",
    "for text in all_text:\n",
    "    new_text = text.split(\", \")\n",
    "    \n",
    "    name = new_text[0]\n",
    "    names.append(name)\n",
    "    date_perct = new_text[1]\n",
    "    cur_stat = new_text[2]\n",
    "    \n",
    "    date_perct = date_perct.split(\" \")\n",
    "    perct = date_perct[0]\n",
    "    percentages.append(perct)\n",
    "    date = date_perct[1]\n",
    "    dates.append(date)\n",
    "    \n",
    "    cur_stat = cur_stat.split(\"\\n\")\n",
    "#     print(cur_stat)\n",
    "    cur = cur_stat[0]\n",
    "    currencies.append(cur)\n",
    "    length = len(cur_stat)\n",
    "    if length == 2:\n",
    "        stat = cur_stat[1]\n",
    "        statuses.append(stat)\n",
    "    elif length == 1:\n",
    "        stat = \"no_status\"\n",
    "        statuses.append(stat)\n",
    "                              \n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds the new variables we scraped into the dataframe\n",
    "scraped_isin_df['names'] = names\n",
    "scraped_isin_df['date'] = dates\n",
    "scraped_isin_df['percent'] = percentages\n",
    "scraped_isin_df['currency'] = currencies\n",
    "scraped_isin_df['status'] = statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exit from the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>urlpath</th>\n",
       "      <th>names</th>\n",
       "      <th>date</th>\n",
       "      <th>percent</th>\n",
       "      <th>currency</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BE0002239086</td>\n",
       "      <td>https://cbonds.com/bonds/178995/</td>\n",
       "      <td>Elia</td>\n",
       "      <td>27may2024</td>\n",
       "      <td>1.375%</td>\n",
       "      <td>EUR</td>\n",
       "      <td>outstanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BE0002256254</td>\n",
       "      <td>https://cbonds.com/bonds/236752/</td>\n",
       "      <td>RESA SA</td>\n",
       "      <td>22jul2026</td>\n",
       "      <td>1%</td>\n",
       "      <td>EUR</td>\n",
       "      <td>outstanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BE0002276450</td>\n",
       "      <td>https://cbonds.com/bonds/308139/</td>\n",
       "      <td>Elia</td>\n",
       "      <td>7apr2027</td>\n",
       "      <td>1.375%</td>\n",
       "      <td>EUR</td>\n",
       "      <td>outstanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BE0002280494</td>\n",
       "      <td>https://cbonds.com/bonds/317929/</td>\n",
       "      <td>GBL</td>\n",
       "      <td>23may2024</td>\n",
       "      <td>1.375%</td>\n",
       "      <td>EUR</td>\n",
       "      <td>outstanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BE0002285543</td>\n",
       "      <td>https://cbonds.com/bonds/321383/</td>\n",
       "      <td>Fluvius System Operator</td>\n",
       "      <td>23jun2025</td>\n",
       "      <td>2%</td>\n",
       "      <td>EUR</td>\n",
       "      <td>outstanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>XS2299001888</td>\n",
       "      <td>https://cbonds.com/bonds/930331/</td>\n",
       "      <td>Italgas</td>\n",
       "      <td>16feb2028</td>\n",
       "      <td>0%</td>\n",
       "      <td>EUR (2556D)</td>\n",
       "      <td>outstanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>XS2299002423</td>\n",
       "      <td>https://cbonds.com/bonds/930335/</td>\n",
       "      <td>Italgas</td>\n",
       "      <td>16feb2033</td>\n",
       "      <td>0.5%</td>\n",
       "      <td>EUR</td>\n",
       "      <td>outstanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>XS2300208928</td>\n",
       "      <td>https://cbonds.com/bonds/930909/</td>\n",
       "      <td>Snam</td>\n",
       "      <td>15aug2025</td>\n",
       "      <td>0%</td>\n",
       "      <td>EUR (1642D)</td>\n",
       "      <td>outstanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>XS2324772453</td>\n",
       "      <td>https://cbonds.com/bonds/958159/</td>\n",
       "      <td>Ferrovie dello Stato</td>\n",
       "      <td>25mar2028</td>\n",
       "      <td>0.375%</td>\n",
       "      <td>EUR</td>\n",
       "      <td>outstanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>XS2332687040</td>\n",
       "      <td>https://cbonds.com/bonds/990197/</td>\n",
       "      <td>INWIT</td>\n",
       "      <td>19apr2031</td>\n",
       "      <td>1.75%</td>\n",
       "      <td>EUR</td>\n",
       "      <td>outstanding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1658 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                           urlpath                    names  \\\n",
       "0     BE0002239086  https://cbonds.com/bonds/178995/                     Elia   \n",
       "1     BE0002256254  https://cbonds.com/bonds/236752/                  RESA SA   \n",
       "2     BE0002276450  https://cbonds.com/bonds/308139/                     Elia   \n",
       "3     BE0002280494  https://cbonds.com/bonds/317929/                      GBL   \n",
       "4     BE0002285543  https://cbonds.com/bonds/321383/  Fluvius System Operator   \n",
       "...            ...                               ...                      ...   \n",
       "1653  XS2299001888  https://cbonds.com/bonds/930331/                  Italgas   \n",
       "1654  XS2299002423  https://cbonds.com/bonds/930335/                  Italgas   \n",
       "1655  XS2300208928  https://cbonds.com/bonds/930909/                     Snam   \n",
       "1656  XS2324772453  https://cbonds.com/bonds/958159/     Ferrovie dello Stato   \n",
       "1657  XS2332687040  https://cbonds.com/bonds/990197/                    INWIT   \n",
       "\n",
       "           date percent     currency       status  \n",
       "0     27may2024  1.375%          EUR  outstanding  \n",
       "1     22jul2026      1%          EUR  outstanding  \n",
       "2      7apr2027  1.375%          EUR  outstanding  \n",
       "3     23may2024  1.375%          EUR  outstanding  \n",
       "4     23jun2025      2%          EUR  outstanding  \n",
       "...         ...     ...          ...          ...  \n",
       "1653  16feb2028      0%  EUR (2556D)  outstanding  \n",
       "1654  16feb2033    0.5%          EUR  outstanding  \n",
       "1655  15aug2025      0%  EUR (1642D)  outstanding  \n",
       "1656  25mar2028  0.375%          EUR  outstanding  \n",
       "1657  19apr2031   1.75%          EUR  outstanding  \n",
       "\n",
       "[1658 rows x 7 columns]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_isin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df to csv file\n",
    "# scraped_isin_df.to_csv (r'/Users/gabbyvinco/Desktop/better_isin_dataset.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique names from scraped_isin_df\n",
    "unique_improved = scraped_isin_df[\"names\"].unique()\n",
    "# unique_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace this one because the previous name was unrecognizable to the API search\n",
    "holding = unique_improved[300]\n",
    "unique_improved[300] = holding.replace(\"Holding de Infrastructures de Transport S.A.S.\",\"Holding d'Infrastructures de Transport S.A.S.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Elia', 'RESA SA', 'GBL', 'Fluvius System Operator', 'Befimmo',\n",
       "       'Anheuser-Busch InBev', 'Brussels Airport', 'Apetra',\n",
       "       'Barry Callebaut Services', 'Solvay', 'Lonza Finance Int',\n",
       "       'Eni Finance', 'VGP NV', 'JAB Holdings',\n",
       "       'TRATON Finance Luxembourg S.A.', 'SIX Finance (Luxembourg)',\n",
       "       'Stellantis', 'BRISA-Concessao Rodoviaria', 'Energias de Portugal',\n",
       "       'Metropolitano de Lisboa', 'NOS SGPS', 'Telecom Italia (TIM)',\n",
       "       'Nederlandse Gasunie', 'Tennet Holding', 'Enexis Holding',\n",
       "       'Alliander', 'Akzo Nobel', 'Nestle S.A.', 'Wolters Kluwer',\n",
       "       'ASML Holding', 'Zapadoslovenska Energetika', 'LafargeHolcim',\n",
       "       'Heineken', 'DSM', 'Royal Dutch Shell', 'Airbus',\n",
       "       'SPP Distribucia', 'Citycon Oyj', 'CNH Industrial', 'Exor NV',\n",
       "       'Novartis', 'Urenco', 'Eurofins Scientific', 'Unilever',\n",
       "       'SPP Infrastructure', 'Redes Energeticas Nacionais (REN)',\n",
       "       'Roche Holding AG', 'NN Group', 'Michelin', 'Adecco',\n",
       "       'Royal Schiphol Group', 'Roche Finance Europe',\n",
       "       'Coca-Cola HBC Finance', 'RELX Finance', 'EDP Finance BV',\n",
       "       'Abb Finance', 'Bunge Ltd', 'Ren Finance', 'Aroundtown',\n",
       "       'Koninklijke KPN', 'Whirlpool', 'Aegon', 'W.P. Carey', 'RELX Plc',\n",
       "       'HeidelbergCement', 'ABB', 'Compass Group', 'ADLER Group S.A.',\n",
       "       'Grand City Properties', 'Philips', 'Deere&Company',\n",
       "       'Koninklijke Ahold Delhaize', 'Stedin Holding', 'PostNL',\n",
       "       'ArcelorMittal', 'Euronext', 'Compagnie Financiere Richemont',\n",
       "       'SES', 'Citycon Treasury', 'PACCAR',\n",
       "       'Compass Group Finance Netherlands',\n",
       "       'Paccar Financial Europe B.V.', 'Coca-Cola HBC AG', 'Schlumberger',\n",
       "       'LyondellBasell Industries',\n",
       "       'Mondelez International Holdings Netherlands',\n",
       "       'CK Hutchison Holdings Limited', 'Digital Realty Trust Inc',\n",
       "       'TE Connectivity', 'PACCAR Financial', 'Givaudan', 'Signify',\n",
       "       'John Deere Capital', 'Schiphol Nederland',\n",
       "       'British American Tobacco', 'Swisscom', 'CRH',\n",
       "       'CPI Property Group', 'Achmea BV', 'Reckitt Benckiser Group',\n",
       "       'Mohawk Industries', 'SIG Combibloc Group AG', 'Eustream',\n",
       "       'Czech Gas Networks Investments', 'Viatris', 'ISS Global',\n",
       "       'NEPI Rockcastle', 'Naspers', 'Heimstaden Bostad',\n",
       "       'Akelius Residential Property', 'Bevco Lux',\n",
       "       'Mondelez International', 'Scandinavian Tobacco', 'CTP B.V.',\n",
       "       'Diageo', 'Global Switch Holdings', 'BP PLC', 'Wizz Air Holdings',\n",
       "       'Sagax', 'H&M Finance', 'EasyJet', 'DSV PANALPINA A/S',\n",
       "       'Simon Property Group L.P.', 'Imperial Brands',\n",
       "       'London Stock Exchange Group', 'SGS S.A.', 'Danfoss', 'EWE',\n",
       "       'Daimler AG', 'Metro AG', 'SAP SE', 'Deutsche Borse',\n",
       "       'Vonovia Finance BV', 'Evonik Finance B.V.', 'BASF',\n",
       "       'Daimler International Finance B.V.', 'Vonovia SE',\n",
       "       'Allianz Finance II B.V.', 'K+S Group', 'Linde',\n",
       "       'Deutsche Boerse AG',\n",
       "       'Siemens Financieringsmaatschappij N.V. (SFM)',\n",
       "       'LEG Immobilien AG', 'Deutsche Wohnen', 'Schaeffler',\n",
       "       'Hochtief AG', 'Deutsche Telekom', 'Vantage Towers', 'Talanx',\n",
       "       'RWE AG', 'EnBW Energie Baden-Wuerttemberg', 'E.ON',\n",
       "       'Deutsche Bahn', 'Deutsche Post', 'Bertelsmann', 'Lanxess AG',\n",
       "       'BMW', 'Robert Bosch', 'Vier Gas Transport', 'Bayer', 'Volkswagen',\n",
       "       'Evonik Industries', 'Infineon Technologies', 'Ceconomy', 'Wuerth',\n",
       "       'Eurogrid', 'Merck KGaA', 'Alstria Office REIT', 'Covestro',\n",
       "       'Linde plc', 'Henkel AG & Co. KGaA', 'Sudzucker', 'Knorr-Bremse',\n",
       "       'Hella KGaA', 'Brenntag', 'Hannover Re Group',\n",
       "       'Amphenol Technologies Holding', 'Fresenius Medical Care',\n",
       "       'Fresenius SE', 'Siemens', 'ZF Friedrichshafen', 'TLG Immobilien',\n",
       "       'Deutsche Lufthansa', 'Continental', 'Albemarle',\n",
       "       'MTU Aero Engines AG', 'Adidas', 'Kion Group', 'Ferrovial',\n",
       "       'Abertis Infraestructuras', 'MAPFRE', 'CORES',\n",
       "       'Inmobiliaria Colonial', 'Telefonica Europe',\n",
       "       'Naturgy Energy Group', 'Telefonica SA',\n",
       "       'Red Electrica Corporacion', 'Repsol', 'Iberdrola', 'Enagas S.A.',\n",
       "       'Redexis Gas', 'Cellnex Telecom', 'Amadeus IT Group',\n",
       "       'Merlin Properties Socimi', 'Madrilena Red de Gas',\n",
       "       'Prosegur Compania de Seguridad SA',\n",
       "       'ACS Actividades de Construccion y Servicios', 'CEPSA',\n",
       "       'International Airlines Group', 'El Corte Ingles',\n",
       "       'NorteGas Energia Distribucion', 'Kaerntner Elektrizitaets AG',\n",
       "       'Novomatic', 'Strabag SE', 'Borealis', 'Vienna Insurance Group',\n",
       "       'Kojamo', 'Metsa Board', 'DNA', 'Energie AG Oberosterreich', 'OMV',\n",
       "       'EVN AG', 'Telekom Austria AG', 'Fingrid OYJ',\n",
       "       'Erdol-Lagergesellschaft', 'Ryanair', 'Sampo Group', 'Verbund',\n",
       "       'TVO', 'Electricity Supply Board (ESB)', 'Kerry Group',\n",
       "       'Eesti Energia', 'DAA', 'PartnerRe', 'Eaton Capital Unlimited',\n",
       "       'GAS Networks Ireland', 'Nokia', 'Elisa',\n",
       "       'Liberty Mutual Finance Europe', 'Stora Enso Oyj', 'Neles',\n",
       "       'Ignitis Group', 'Elering', 'Fortum Oyj',\n",
       "       'Zurich Finance (Ireland)', 'Atlas Copco', 'CA Immobilien',\n",
       "       'Mondi AG', 'SATO', 'Uniqa Insurance', 'Glencore International AG',\n",
       "       'Immofinanz', 'UPM', 'Hemso Treasury', 'Balder',\n",
       "       'Samhallsbyggnadsbolaget i Norden', 'Orange', 'Engie', 'La Poste',\n",
       "       'Veolia Environnement', 'Cofiroute',\n",
       "       'Autoroutes Du Sud de La France', 'SUEZ',\n",
       "       'Electricite de France (EDF)',\n",
       "       \"RTE Reseau de Transport d'electricite\", 'SAGESS', 'Bouygues',\n",
       "       'Aeroports de Paris', 'Eutelsat', 'Air Liquide Finance',\n",
       "       'Air Liquide', 'Gecina', 'Danone', 'Schneider Electric', 'Sanofi',\n",
       "       'Valeo', 'ESSILORLUXOTTICA', 'LVMH Moet Hennessy Louis Vuitton',\n",
       "       'Pernod Ricard', 'Kering', 'Wendel', 'Infra Foch', 'Klepierre',\n",
       "       'Mercialys', 'Societe Fonciere Lyonnaise', 'Publicis Groupe',\n",
       "       'Arkema', 'Edenred', 'Transport et Infrastructures Gaz France',\n",
       "       'CARMILA', 'Sanef SA', 'Legrand', 'Covivio (Fonciere des Regions)',\n",
       "       'Vivendi', 'JCDecaux', 'APRR',\n",
       "       'Regie Autonome des Transports Parisiens', 'Capgemini', 'Renault',\n",
       "       \"Coentreprise De Transport D'electricite\",\n",
       "       \"Holding d'Infrastructures de Transport S.A.S.\", 'Thales',\n",
       "       'Infra Park', 'Unibail-Rodamco SE', 'Carrefour', 'Altareit',\n",
       "       'Covivio Hotels', 'VINCI SA', 'AtoS', 'Dassault Systemes',\n",
       "       'Worldline', 'Alstom', 'Ceetrus', 'Terega SAS', 'SNCF', 'Auchan',\n",
       "       'Teleperformance', 'Altarea', 'Safran S.A.', 'Total', 'Sodexo',\n",
       "       'WPP', 'AXA', 'Compagnie De St-Gobain', 'Cie De Saint-Gobain',\n",
       "       'Schlumberger Holdings Corporation', 'Firmenich International',\n",
       "       'Autostrade', 'Enel', 'Atlantia', 'Terna SPA', 'Leonardo',\n",
       "       'Assicurazioni Generali', 'Snam', 'Hera', 'Eni Spa',\n",
       "       'Ferrovie dello Stato', 'A2A', 'Luxottica', 'Iren S.p.A.', 'Acea',\n",
       "       '2i rete gas', 'Buzzi Unicem', 'Italgas', 'Aeroporti di Roma',\n",
       "       'Esselunga', 'ERG SPA', 'Radiotelevisione Italiana (RAI)', 'INWIT',\n",
       "       'Poste Italiane'], dtype=object)"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_improved = pd.DataFrame(unique_improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the unique_improved to csv file\n",
    "# unique_improved.to_csv (r'/Users/gabbyvinco/Desktop/cbonds_list.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Selenium to scrape boerse-frankfurt for names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and initiate driver\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to test the individual sneaker page functions\n",
    "my_url = \"https://www.boerse-frankfurt.de/bond/fr0011225143-electricite-de-france-s-a-e-d-f-4-125-12-27\"\n",
    "\n",
    "# open and maximize the browser window\n",
    "driver.get(my_url)\n",
    "# driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the action object\n",
    "action = webdriver.ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a wait with a 5 second timeout\n",
    "wait = WebDriverWait(driver, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of ISIN numbers\n",
    "isin_list = corporate_bond_holdings_df['ISIN'].tolist()\n",
    "# isin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists for the function to append to\n",
    "text_list = []\n",
    "no_entries_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to navigate boerse-frankfurt search bar and grab basic info from popdown\n",
    "def scrape_boerse_names(isin_list):\n",
    "    for isin in isin_list:\n",
    "        \n",
    "        search_bar = wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/app-root/app-wrapper/div/div[1]/app-header/div[2]/div[2]/div/app-global-search-field-widget/div/form/mat-form-field/div/div[1]/div/input')))\n",
    "        \n",
    "        # click search bar\n",
    "        search_bar.click()\n",
    "        \n",
    "        # random sleep time between 1 and 2 seconds\n",
    "        sleep(randint(1,2))\n",
    "        \n",
    "        # type in isin number\n",
    "        search_bar.send_keys(isin)\n",
    "        \n",
    "        # time sleep 5 seconds\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # grab info from isin entry pop down\n",
    "        try:\n",
    "            pop_down = driver.find_element_by_xpath('/html/body/div/div/div/div/mat-option/span/div/div[1]')\n",
    "            text = pop_down.text  \n",
    "            text_list.append(text)\n",
    "            print(text)\n",
    "        except:\n",
    "            # select all text in the search bar and delete\n",
    "            no_entries_list.append(isin)\n",
    "            search_bar.send_keys(Keys.COMMAND, 'a')\n",
    "            search_bar.send_keys(Keys.BACKSPACE)\n",
    "            continue\n",
    "        \n",
    "        # random sleep time between 2 and 4 seconds\n",
    "        sleep(randint(2,4))\n",
    "        \n",
    "        # select all text in the search bar and delete\n",
    "        search_bar.send_keys(Keys.COMMAND, 'a')\n",
    "        search_bar.send_keys(Keys.BACKSPACE)\n",
    "        \n",
    "        \n",
    "        # random sleep time between 2 and 5 seconds\n",
    "        sleep(randint(2,5))\n",
    "    \n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_boerse_names(isin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exit from the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list to dataframe just incase I accidentally delete/overwrite it\n",
    "boerse_df = pd.DataFrame(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the boerse_df to csv file\n",
    "# boerse_df.to_csv (r'/Users/gabbyvinco/Desktop/boerse_text_list.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists to append the split items to \n",
    "issue_year = []\n",
    "maturation_year = []\n",
    "name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the items in the scraped list\n",
    "for item in text_list:\n",
    "    date = item[-5:]\n",
    "    date = date.split(\"/\")\n",
    "    issue_year.append(date[0])\n",
    "    maturation_year.append(date[1])\n",
    "    item = item[:-5]\n",
    "    name.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the new lists to the dataframe\n",
    "boerse_df[\"IssueYear\"] = issue_year\n",
    "boerse_df[\"MaturationYear\"] = maturation_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new lists to append the split items to\n",
    "company_name = []\n",
    "interest_rate = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the items in the scraped list\n",
    "for item in name:\n",
    "    item = item.split(\",\")\n",
    "#     print(item)\n",
    "    if len(item) > 1:\n",
    "        decimal = item[1]\n",
    "#         print(decimal)\n",
    "        first_part = item[0]\n",
    "        integer = first_part[-1]\n",
    "        company = first_part[:-2]\n",
    "        interest = integer +\".\"+ decimal\n",
    "        company_name.append(company)\n",
    "        interest_rate.append(interest)\n",
    "    if len(item) == 1 :\n",
    "        not_split = item[0]\n",
    "        percent = not_split[-3:]\n",
    "#         print(percent)\n",
    "        company = not_split[:-3]\n",
    "#         print(company)\n",
    "        company_name.append(company)\n",
    "        interest_rate.append(integer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to append item to\n",
    "fixed_comp_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extra space on the end if its there\n",
    "for item in company_name:\n",
    "    if item[-1] == \" \":\n",
    "        item = item[:-1]\n",
    "        fixed_comp_name.append(item)\n",
    "    else:\n",
    "        fixed_comp_name.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_comp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to append item to\n",
    "comp_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove square brackets because it was giving the API search issues\n",
    "for item in fixed_comp_name:\n",
    "    item = item.replace(\" [GBL]\",\"\")\n",
    "    item = item.replace(\"[\", \"(\")\n",
    "    item = item.replace(\"]\", \")\")\n",
    "    comp_name.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lists to dataframe\n",
    "boerse_df[\"CompanyName\"] = comp_name\n",
    "boerse_df[\"InterestRate\"] = interest_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneccesary column\n",
    "boerse_df = boerse_df.drop(boerse_df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "cols = [\"CompanyName\", \"InterestRate\",\"IssueYear\",\"MaturationYear\"]\n",
    "boerse_df = boerse_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boerse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique company names\n",
    "boerse_unique = boerse_df[\"CompanyName\"]\n",
    "boerse_unique = boerse_unique.unique()\n",
    "boerse_unique = boerse_unique.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the ISIN codes that didn't produce a result on boerse-frankfurt\n",
    "missing_from_boerse = pd.DataFrame(no_entries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_from_boerse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to append to and a count so that we can use it as an index to access the same\n",
    "count = 0\n",
    "missing_boerse_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I fixed an error here, but to check if it is right I have to run the scraper all over again because I forgot to save no_entries_list before. It takes a few hours to run and I don't want to run it again if its not absolutely neccesary.\n",
    "\n",
    "### So everything from here on out for this section (boerse-frankfurt) is going to change. the results you see below are probably not correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should connect the isin code we have here in the no_entries_list to the company name in the OG excel sheet\n",
    "\n",
    "for code in no_entries_list:\n",
    "    count = 0\n",
    "    for isin in isin_list:\n",
    "        count += 1\n",
    "        if code == isin:\n",
    "            name = corporate_bond_holdings_df['ISSUER'][count]\n",
    "            missing_boerse_names.append(name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_from_boerse[\"names\"] = missing_boerse_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_names = missing_from_boerse[\"names\"].unique()\n",
    "# missing_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_missing = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in missing_names:\n",
    "    item = item.replace(\"√°\",\"a\")\n",
    "    item = item.replace(\"√£\", \"a\")\n",
    "    item = item.replace(\"√©\", \"e\")\n",
    "    item = item.replace(\"Intl\", \"International\")\n",
    "    item = item.replace(\"Luxembg\", \"Luxembourg\")\n",
    "    item = item.replace(\"Luxemburg\", \"Luxembourg\")\n",
    "    fixed_missing.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = boerse_unique + fixed_missing\n",
    "# all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_boerse_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in all_companies:\n",
    "    item = item.replace(\".\",\"\")\n",
    "    final_boerse_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_boerse_list = set(final_boerse_list)\n",
    "len(final_boerse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_boerse = pd.DataFrame(final_boerse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the unique_improved to csv file\n",
    "# final_boerse.to_csv (r'/Users/gabbyvinco/Desktop/boerse_list.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
